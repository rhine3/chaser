{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of lines in file\n",
    "\n",
    "```\n",
    "data_file = '/Volumes/seagate-storage/code/ebird_data/ebd_relJan-2019.txt'\n",
    "count = 0\n",
    "for line in open(data_file): count += 1\n",
    "```\n",
    "\n",
    "After this, `count` = 577335302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out which columns to store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save:\n",
    "* `LAST EDITED DATE`\n",
    "* `CATEGORY`\n",
    "* `COMMON NAME`\n",
    "* `OBSERVATION COUNT`\n",
    "* `COUNTY CODE`\n",
    "* `LATITUDE`\n",
    "* `LONGITUDE`\n",
    "* `OBSERVATION DATE`\n",
    "* `TIME OBSERVATIONS STARTED`\n",
    "* `OBSERVER ID`\n",
    "* `SAMPLING EVENT IDENTIFIER`\n",
    "* `PROTOCOL TYPE`\n",
    "* `DURATION MINUTES`\n",
    "* `NUMBER OBSERVERS`\n",
    "* `ALL SPECIES REPORTED`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL UNIQUE IDENTIFIER\tLAST EDITED DATE\tTAXONOMIC ORDER\tCATEGORY\tCOMMON NAME\tSCIENTIFIC NAME\tSUBSPECIES COMMON NAME\tSUBSPECIES SCIENTIFIC NAME\tOBSERVATION COUNT\tBREEDING BIRD ATLAS CODE\tBREEDING BIRD ATLAS CATEGORY\tAGE/SEX\tCOUNTRY\tCOUNTRY CODE\tSTATE\tSTATE CODE\tCOUNTY\tCOUNTY CODE\tIBA CODE\tBCR CODE\tUSFWS CODE\tATLAS BLOCK\tLOCALITY\tLOCALITY ID\t LOCALITY TYPE\tLATITUDE\tLONGITUDE\tOBSERVATION DATE\tTIME OBSERVATIONS STARTED\tOBSERVER ID\tSAMPLING EVENT IDENTIFIER\tPROTOCOL TYPE\tPROTOCOL CODE\tPROJECT CODE\tDURATION MINUTES\tEFFORT DISTANCE KM\tEFFORT AREA HA\tNUMBER OBSERVERS\tALL SPECIES REPORTED\tGROUP IDENTIFIER\tHAS MEDIA\tAPPROVED\tREVIEWED\tREASON\tTRIP COMMENTS\tSPECIES COMMENTS\n",
      "URN:CornellLabOfOrnithology:EBIRD:OBS34169564\t2014-10-16 08:19:55\t6171\tspecies\tBonaparte's Gull\tChroicocephalus philadelphia\t\t\t6\t\t\t\tCanada\tCA\tQuebec\tCA-QC\tNicolet-Yamaska\tCA-QC-NY\t\t\t\t\tPort St-François\tL352699\tP\t46.2722222\t-72.6111111\t2006-10-14\t10:00:00\tobsr31597\tS2495584\tTraveling\tP22\tEBIRD_CAN\t60\t1\t\t1\t0\t\t0\t1\t0\t\tTerns are late!\t\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -2 /Volumes/seagate-storage/code/ebird_data/ebd_relJan-2019.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text format:\n",
    "\n",
    "```\n",
    "GLOBAL UNIQUE IDENTIFIER\t                    LAST EDITED DATE\t        TAXONOMIC ORDER\t    CATEGORY\t    COMMON NAME\t        SCIENTIFIC NAME\t               SUBSPECIES COMMON NAME\tSUBSPECIES SCIENTIFIC NAME\tOBSERVATION COUNT\tBREEDING BIRD ATLAS CODE\tBREEDING BIRD ATLAS CATEGORY\tAGE/SEX\tCOUNTRY\tCOUNTRY CODE\tSTATE\tSTATE CODE\tCOUNTY\t            COUNTY CODE\tIBA CODE\tBCR CODE\tUSFWS CODE\tATLAS BLOCK\tLOCALITY\t        LOCALITY ID\tLOCALITY TYPE\tLATITUDE\tLONGITUDE\tOBSERVATION DATE\tTIME OBSERVATIONS STARTED\tOBSERVER ID\tSAMPLING EVENT IDENTIFIER\tPROTOCOL TYPE\tPROTOCOL CODE\tPROJECT CODE\tDURATION MINUTES\tEFFORT DISTANCE KM\tEFFORT AREA HA\tNUMBER OBSERVERS\tALL SPECIES REPORTED\tGROUP IDENTIFIER\tHAS MEDIA\tAPPROVED\tREVIEWED\tREASON\tTRIP COMMENTS\tSPECIES COMMENTS\n",
    "URN:CornellLabOfOrnithology:EBIRD:OBS34169564\t2014-10-16 08:19:55\t        6171\t            species\t        Bonaparte's Gull\tChroicocephalus philadelphia\t\t                    \t                        6\t                \t                        \t                        \t        Canada\tCA\t            Quebec\tCA-QC\t     Nicolet-Yamaska\tCA-QC-NY\t\t        \t        \t        \t        Port St-François\tL352699\t    P\t            46.2722222\t-72.6111111\t2006-10-14\t         10:00:00\t                obsr31597\tS2495584\t                Traveling\t    P22\t            EBIRD_CAN\t    60\t                1\t                \t            1\t                0\t                    \t                0\t        1\t        0\t        \t    Terns are late!\t\n",
    "```\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store entire ebird database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of columns for each type of database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "desired_cols_comprehensive = [\n",
    "    'LAST EDITED DATE', #For telling whether or not the observation was submitted in 2018\n",
    "    'CATEGORY', #Species or no? (not sure how others are represented)\n",
    "    'COMMON NAME', \n",
    "    'OBSERVATION COUNT', #Number of individuals seen--or X'd (not sure how represented)\n",
    "    'STATE CODE', #Something like US-PA-AL. Not sure if every obs has a county...\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'OBSERVATION DATE',\n",
    "    'TIME OBSERVATIONS STARTED',\n",
    "    'OBSERVER ID',\n",
    "    'SAMPLING EVENT IDENTIFIER', #The checklist itself... Not sure if there are anything besides S_____ formatted labels, and what the difference is from global unique identifier (maybe the latter is for the single species obs)\n",
    "    'PROTOCOL TYPE', #Traveling... or something else? Not sure what else is out there\n",
    "    'DURATION MINUTES', #To see if it has both a start and end time\n",
    "    'NUMBER OBSERVERS', #Not sure if each observer's list is counted as a separate observation, or if only the originally submitting observer's is included\n",
    "    'ALL SPECIES REPORTED',\n",
    "]\n",
    "'''\n",
    "# A subset of desired_cols_comprehensive; pared down for speed\n",
    "desired_cols_chaser = {\n",
    "    'CATEGORY':'str', #Species or no? (not sure how others are represented)\n",
    "    'COMMON NAME':'str',\n",
    "    'OBSERVATION COUNT':'str', #Number of individuals seen--or X'd (not sure how represented)\n",
    "    'STATE CODE':'str', #Something like US-PA-AL. Not sure if every obs has a county...\n",
    "    'LATITUDE':'str',\n",
    "    'LONGITUDE':'str',\n",
    "    'OBSERVATION DATE':'str',\n",
    "    'SAMPLING EVENT IDENTIFIER':'str', #The checklist itself... Not sure if there are anything besides S_____ formatted labels, and what the difference is from global unique identifier (maybe the latter is for the single species obs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for `pd.read_csv` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to read from\n",
    "data_file = '/Volumes/seagate-storage/code/ebird_data/ebd_relJan-2019.txt'\n",
    "\n",
    "# Which columns to use\n",
    "desired_cols = desired_cols_chaser\n",
    "                          \n",
    "# Of columns, which are dates?\n",
    "date_cols = ['OBSERVATION DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk size to read through data_file\n",
    "chunk_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for `pd.to_sql` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired path for SQLITE db; if does not exist, will be created\n",
    "engine_path = \"/Volumes/seagate-storage/db/ebird.db\"\n",
    "\n",
    "# Name of SQL table\n",
    "table_name = '20180329'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many chunks to print after\n",
    "X = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, save to database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "  Lines saved to DB: 10000\n",
      "  Minutes elapsed: 0.009690447648366293\n",
      "\n",
      "Iteration 5000:\n",
      "  Lines saved to DB: 50010000\n",
      "  Minutes elapsed: 18.879338264465332\n",
      "\n",
      "Iteration 10000:\n",
      "  Lines saved to DB: 100010000\n",
      "  Minutes elapsed: 44.32478020191193\n",
      "\n",
      "Iteration 15000:\n",
      "  Lines saved to DB: 150010000\n",
      "  Minutes elapsed: 62.60856884717941\n",
      "\n",
      "Iteration 20000:\n",
      "  Lines saved to DB: 200010000\n",
      "  Minutes elapsed: 80.8412572145462\n",
      "\n",
      "Iteration 25000:\n",
      "  Lines saved to DB: 250010000\n",
      "  Minutes elapsed: 98.16712503433227\n",
      "\n",
      "Iteration 30000:\n",
      "  Lines saved to DB: 300010000\n",
      "  Minutes elapsed: 115.19377500216166\n",
      "\n",
      "Iteration 35000:\n",
      "  Lines saved to DB: 350010000\n",
      "  Minutes elapsed: 132.49426699876784\n",
      "\n",
      "Iteration 40000:\n",
      "  Lines saved to DB: 400010000\n",
      "  Minutes elapsed: 150.45156251589458\n",
      "\n",
      "Iteration 45000:\n",
      "  Lines saved to DB: 450010000\n",
      "  Minutes elapsed: 167.80280270179114\n",
      "\n",
      "Iteration 50000:\n",
      "  Lines saved to DB: 500010000\n",
      "  Minutes elapsed: 185.08012558619183\n",
      "\n",
      "Iteration 55000:\n",
      "  Lines saved to DB: 550010000\n",
      "  Minutes elapsed: 202.18646633227667\n",
      "\n",
      "Total iterations: 57734\n",
      "Total lines saved to DB: 577335301\n",
      "Minutes elapsed during DB functions: 212.54126666784288\n",
      "Total minutes elapsed: 212.5414152344068\n",
      "Estimated time for all lines: 3.542356926709144 hours\n"
     ]
    }
   ],
   "source": [
    "def process_data(\n",
    "    engine_path,\n",
    "    data_path,\n",
    "    desired_cols,\n",
    "    date_cols,\n",
    "    chunk_size,\n",
    "    table_name,\n",
    "    X,\n",
    "    delete_old_table = True\n",
    "):\n",
    "    t0 = time()\n",
    "    \n",
    "    engine = create_engine('sqlite:///' + engine_path)\n",
    "    # If database doesn't already exist, make a new engine\n",
    "    if not database_exists(engine.url):\n",
    "        create_database(engine.url)\n",
    "    # Otherwise, make sure the engine is clear\n",
    "    # Note that it's MUCH faster to delete this from filesystem directly\n",
    "    elif delete_old_table:\n",
    "        meta = MetaData(engine)\n",
    "        meta.reflect() # Find all tables\n",
    "        # Only drop the table we're trying to refill\n",
    "        for tbl in reversed(meta.sorted_tables):\n",
    "            if tbl.name == table_name:\n",
    "                engine.execute(tbl.delete())\n",
    "                print(f'Dropped table {table_name}')\n",
    "        \n",
    "    t1 = time()\n",
    "    \n",
    "    lines_saved_to_db = 0\n",
    "    counter = 0\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        filepath_or_buffer = data_path, \n",
    "        sep = '\\t',\n",
    "        usecols = desired_cols.keys(),\n",
    "        parse_dates = date_cols, \n",
    "        chunksize = chunk_size,\n",
    "        dtype = desired_cols,\n",
    "        na_values = ['X']\n",
    "    ):\n",
    "\n",
    "        chunk.to_sql(\n",
    "            name = table_name,\n",
    "            con = engine,\n",
    "            if_exists = 'append'\n",
    "        )\n",
    "\n",
    "        # Print info every X iterations\n",
    "        # i.e., every chunk_size * X lines\n",
    "        lines_saved_to_db += chunk.shape[0]\n",
    "        if (not counter % X):\n",
    "            print(f\"Iteration {counter}:\")\n",
    "            print(f\"  Lines saved to DB: {lines_saved_to_db}\") #Helpful for only saving year data\n",
    "            print(f\"  Minutes elapsed: {(time()-t1)/60}\\n\")\n",
    "        counter += 1\n",
    "\n",
    "    db_time = (time()-t1)/60\n",
    "    total_time = (time()-t0)/60\n",
    "    estimated_time = ((total_time-db_time) +  (577335302/lines_saved_to_db)*db_time)/60\n",
    "    print(f\"Total iterations: {counter}\")\n",
    "    print(f\"Total lines saved to DB: {lines_saved_to_db}\") #Helpful for only saving year data\n",
    "    print(f\"Minutes elapsed during DB functions: {db_time}\")\n",
    "    print(f\"Total minutes elapsed: {total_time}\")\n",
    "    print(f\"Estimated time for all lines: {estimated_time} hours\")\n",
    "    return engine\n",
    "            \n",
    "engine = process_data(\n",
    "    engine_path,\n",
    "    data_file,\n",
    "    desired_cols,\n",
    "    date_cols,\n",
    "    chunk_size,\n",
    "    table_name,\n",
    "    X\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try chaser on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import vincenty\n",
    "import datetime\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done below:\n",
    "```\n",
    "show_unique(series)\n",
    "identify_centers(df, radius_miles=5)\n",
    "select_loc_df(df, my_dict, center)\n",
    "select_date_df(df, month, day, interval=4)\n",
    "calculate_score(df)\n",
    "interval_without_year(date1, date2)\n",
    "analyze_data(\n",
    "    df,\n",
    "    lifelist_path,\n",
    "    month,\n",
    "    day,\n",
    "    radius_miles)\n",
    "def import_data(\n",
    "    engine_path,\n",
    "    table_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique(series):\n",
    "    '''\n",
    "    Return a list of the unique elements in a pandas series\n",
    "    '''\n",
    "    \n",
    "    all_elements = list(series)\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    unique_elements = [x for x in all_elements if not (x in seen or seen_add(x))]\n",
    "\n",
    "    return unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_centers(df, radius_miles = 5):\n",
    "    '''\n",
    "    Create a dictionary where the\n",
    "        keys = centers,\n",
    "        values = list of points within the desired radius\n",
    "    '''\n",
    "    \n",
    "    # Create a list of all unique points to use for our centers\n",
    "    all_points = show_unique(df['LOCATION'])\n",
    "    centers = all_points #TODO: create a more efficient center-finding algo\n",
    "\n",
    "    my_dict = {}\n",
    "    centers = all_points\n",
    "    for center in centers:\n",
    "        close_points = []\n",
    "        for point in all_points:\n",
    "            try:\n",
    "                distance = vincenty(center, point, miles=True)\n",
    "            except ValueError: #ValueError: Vincenty formula failed to converge!\n",
    "                distance = np.NaN\n",
    "            if distance < radius_miles:\n",
    "                close_points.append(point)\n",
    "\n",
    "        my_dict[center] = close_points\n",
    "        \n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_loc_df(df, my_dict, center): \n",
    "    '''\n",
    "    Select relevant sightings by location\n",
    "    \n",
    "    For a single center (key), return a DF with only:\n",
    "    - sightings from locations in the desired radius (value) \n",
    "    - sightings from a desired date range\n",
    "    \n",
    "    Inputs:\n",
    "        df: the full dataframe to select sightings from\n",
    "        my_dict: the dictionary associating centers with lists\n",
    "            of points within the radius\n",
    "        center: the specific dictionary key to use\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Select only locations corresponding to radius around the center\n",
    "    return df[df['LOCATION'].isin(my_dict[center])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_date_df(df, month, day, interval=4): \n",
    "    '''\n",
    "    Select relevant sightings by date\n",
    "    \n",
    "    For a single center (key), return a DF with only sightings from a desired date range\n",
    "    \n",
    "    Inputs:\n",
    "        df: the full dataframe to select sightings from\n",
    "        month, day: the date to center a date range around\n",
    "        interval: the number of days before & after the specified\n",
    "            date to include sightings from\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Select only locations within date range\n",
    "    desired_date=datetime.date(2019, month, day) #2019 is a placeholder year\n",
    "\n",
    "    df['INTERVAL'] = df['OBSERVATION DATE'].apply(interval_without_year, date2=desired_date)\n",
    "    selected_sightings = df.loc[df['INTERVAL'] <= interval]\n",
    "    \n",
    "     \n",
    "    return selected_sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_total_spp(df):\n",
    "    '''\n",
    "    Calculate score of DF based on # species\n",
    "    \n",
    "    Calculate score of a DF solely by how many\n",
    "    unique species are in the 'COMMON NAME' column.\n",
    "    \n",
    "    Inputs:\n",
    "        df: a dataframe with a column 'COMMON NAME'. This df should\n",
    "        contain one column for each individual observation of a species.\n",
    "        \n",
    "    Returns: \n",
    "    '''\n",
    "    \n",
    "    # Create DF associating common name with count of lists\n",
    "    #(to maintain compliance with other scoring functions)\n",
    "    collapsed_df = df['COMMON NAME'].value_counts()\n",
    "    \n",
    "    # Calculate true score\n",
    "    score = len(show_unique(df['COMMON NAME']))\n",
    "    \n",
    "    return score, collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_num_lists(df):\n",
    "\n",
    "    '''\n",
    "    Calculate score of DF based on # lists\n",
    "    \n",
    "    Calculate the score of a DF by finding\n",
    "    the number of checklists on which a species was reported.\n",
    "    This could be modified to be more sophisticated in the future.\n",
    "    \n",
    "    Inputs:\n",
    "        df: a dataframe with a column 'COMMON NAME'. This df should\n",
    "            contain one column for each individual observation of a species.\n",
    "    \n",
    "    Outputs:\n",
    "        the sum of the number of checklists each species\n",
    "        appeared on--which is identical to df.shape[0]\n",
    "    '''\n",
    "    \n",
    "    # Create DF associating common name with count of lists\n",
    "    collapsed_df = df['COMMON NAME'].value_counts()\n",
    "    \n",
    "    # Calculate true score\n",
    "    score = sum(collapsed_df)\n",
    "    \n",
    "    return score, collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_without_year(date1, date2):\n",
    "    '''\n",
    "    Return number of days between two dates\n",
    "    \n",
    "    Returns interval of days between two dates regardless of year. \n",
    "    For instance, January 1, 2019 and January 4, 1999 are considered \n",
    "    3 days apart with this method, no matter which one is provided\n",
    "    as day1 or day2.\n",
    "    \n",
    "    This function may be imperfect WRT leap years.\n",
    "    \n",
    "    Inputs:\n",
    "        date1, date2: datetime.date objects\n",
    "        \n",
    "    Returns:\n",
    "        number of days between them on calendar (regardless of year)\n",
    "    \n",
    "    '''\n",
    "    date1 = date1.date()\n",
    "    delta = date1-date2\n",
    "    way1 = delta.days % 365\n",
    "    way2 = 365-way1\n",
    "    \n",
    "    if way1 < way2: return way1\n",
    "    else: return way2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(\n",
    "    df,\n",
    "    lifelist_path,\n",
    "    month,\n",
    "    day,\n",
    "    padding,\n",
    "    radius_miles,\n",
    "    scoring_method = 'total' #or 'lists'\n",
    "):\n",
    "    '''\n",
    "    Find best area for a given month, day, and radius\n",
    "    \n",
    "    Inputs\n",
    "        df: dataframe of eBird observations generated by import_data\n",
    "        lifelist_path: path to .csv of life list file. Species should be in format:\n",
    "            'Black-bellied Whistling-Duck - Dendrocygna autumnalis' (without quotes)\n",
    "        month: numerical month of 'center date' around which to search for hotspots\n",
    "        day: numerical day of 'center date' around which to search for hotspots\n",
    "        padding: how many days before and after the 'center date' the observations should include\n",
    "        radius_miles: how large of a radius do you want to search within\n",
    "        scoring_method: how to score hotspots\n",
    "            total: just based on the total number of species\n",
    "            lists: based on how many lists each lifer appeared\n",
    "        \n",
    "    Returns (all_dfs, all_scores)\n",
    "        all_dfs: a dataframe for every center\n",
    "        all_scores: a score for every center\n",
    "    '''\n",
    "    \n",
    "    # Generate list of lifers from .csv file\n",
    "    life_list = []\n",
    "    with open(lifelist_path) as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        # Handle different eBird life list formats\n",
    "        next(reader) # Skip line 0, the header\n",
    "        test_bird = next(reader)[1]\n",
    "        f.seek(1) # Go back to line 1, the first data row\n",
    "        # For scientific names\n",
    "        if ' - ' in test_bird:\n",
    "            for line in reader:\n",
    "                bird = ' '.join(line[1].split()[:-3])\n",
    "                life_list.append(str(bird).lower()) \n",
    "                \n",
    "        # For no scientific names:\n",
    "        else:\n",
    "            for line in reader:\n",
    "                bird = line[1]\n",
    "                life_list.append(str(bird).lower()) \n",
    "        \n",
    "        \n",
    "\n",
    "    # Remove species that are already on one's life list\n",
    "    df = df[~df['COMMON NAME'].str.lower().isin(life_list)]\n",
    "    \n",
    "    \n",
    "    # Remove checklists from outside of this date range\n",
    "    df = select_date_df(df, month, day, interval=4)\n",
    "    \n",
    "    \n",
    "    # Identify a dict of centers\n",
    "    my_dict = identify_centers(df, radius_miles)\n",
    "    \n",
    "    \n",
    "    # For each center, generate a relevant DF and calculate its score\n",
    "    all_dfs = {}\n",
    "    all_scores = {}\n",
    "    for center in my_dict.keys():\n",
    "        \n",
    "        # Select only locations within radius\n",
    "        selected_df = select_loc_df(df, my_dict, center)\n",
    "        \n",
    "        # Calculate score and 'collapsed DF', which is a dataframe\n",
    "        # associating each species with the number of checklists it appeared on\n",
    "        if scoring_method == 'lists':\n",
    "            score, collapsed_df = calculate_score_num_lists(selected_df)\n",
    "        else:\n",
    "            score, collapsed_df = calculate_score_total_spp(selected_df)\n",
    "        \n",
    "        # Create dictionaries associating centers with their scores & collapsed dfs\n",
    "        all_scores[center] = score\n",
    "        all_dfs[center] = collapsed_df\n",
    "        \n",
    "    \n",
    "    return (all_dfs, all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(\n",
    "    engine_path,\n",
    "    table_name,\n",
    "):\n",
    "    '''\n",
    "    Import and clean dataset from database.\n",
    "    \n",
    "    Import a dataset from a database. Add a location column and remove\n",
    "    extraneous records (spuhs, slashes, hybrids, domestics) from dataset.\n",
    "    \n",
    "    Inputs\n",
    "        engine_path: path to db location, e.g. '/Volumes/storage/data.db'\n",
    "        table_name: the name of the table in this database, e.g. 'usa_only'\n",
    "        \n",
    "    Returns\n",
    "        a rough database\n",
    "    '''\n",
    "    \n",
    "    # Import data\n",
    "    engine = create_engine('sqlite:///' + engine_path)\n",
    "    rough_df = pd.read_sql(table_name, con = engine)\n",
    "    \n",
    "    # Add location column\n",
    "    rough_df['LOCATION'] = rough_df.apply(lambda row: (row['LATITUDE'], row['LONGITUDE']), axis=1)\n",
    "    \n",
    "    # Remove spuhs, slashes, domestics, and hybrids to leave only species, issf, and form\n",
    "    return rough_df[~rough_df['CATEGORY'].isin(['spuh', 'domestic', 'slash', 'hybrid'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chaser(\n",
    "    engine_path,\n",
    "    table_name,\n",
    "    lifelist_filename,\n",
    "    month,\n",
    "    day,\n",
    "    padding,\n",
    "    num_spots,\n",
    "    radius_miles,\n",
    "    scoring_method = 'total' #or 'lists'\n",
    "):\n",
    "    \n",
    "    '''\n",
    "    Find the best places to go for your life list\n",
    "    \n",
    "    Inputs\n",
    "        engine_path: path to database of all observations, e.g. '/Volumes/storage/all_data.db'\n",
    "        table_name: name of relevant table within database, e.g. 'usa_only_table'\n",
    "        lifelist_filename: path to .csv file containing a single column\n",
    "            All species must be in format: 'Black-bellied Whistling-Duck - Dendrocygna autumnalis'\n",
    "            To create a file like this, download your life list, then copy and paste the 'Species'\n",
    "            column into a new .csv. Do not include the 'species' header (though it won't make a difference).\n",
    "            Life list can be downloaded at https://ebird.org/MyEBird?cmd=lifeList&listType=world&listCategory=default&time=life\n",
    "        month: numerical month in which to search for lifer spots\n",
    "        day: numerical day around which to search for lifer spots\n",
    "        padding: number of days before and after month/day to search for lifer spots\n",
    "        num_spots: number of top spots to show\n",
    "        radius_miles: miles within which you are willing to bird\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Get DF of data\n",
    "    my_df = import_data(engine_path, table_name)\n",
    "    \n",
    "    # Only look for places in the USA (#ABAcentrism)\n",
    "    my_df = my_df[(my_df['STATE CODE'].str.contains('US-')) & (~my_df['STATE CODE'].str.contains('US-HI'))]\n",
    "\n",
    "    # Get dict of dfs of highest-scoring spots\n",
    "    dfs, scores = analyze_data(\n",
    "        df = my_df,\n",
    "        lifelist_path = lifelist_filename, \n",
    "        month = month,\n",
    "        day = day,\n",
    "        padding = padding,\n",
    "        radius_miles = radius_miles,\n",
    "        scoring_method = scoring_method)\n",
    "\n",
    "\n",
    "    # Sort by scores\n",
    "    #sorted_d = sorted(((value, key) for (key,value) in scores.items()), reverse=True)\n",
    "    \n",
    "    # Sort by number of targets\n",
    "    sorted_d = sorted(((value, key) for (key,value) in scores.items()), reverse=True)\n",
    "\n",
    "    if len(sorted_d) < num_spots:\n",
    "        num_to_show = len(sorted_d)\n",
    "    else:\n",
    "        num_to_show = num_spots\n",
    "\n",
    "    for i in range(num_to_show):\n",
    "        center =  sorted_d[i][1]\n",
    "\n",
    "        # Identify most common targets\n",
    "        center_df = dfs[center]\n",
    "        top_10percent = math.ceil(.1 * center_df.size)\n",
    "        targets = list(center_df.reset_index()['index'][0:])\n",
    "\n",
    "        print('Top spot {}:'.format(i+1), center)\n",
    "        print('Number possible targets:', len(targets))\n",
    "        print('Most common targets:', targets)\n",
    "        print('')\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = \"/Volumes/seagate-storage/db/ebird_small.db\"\n",
    "table_name = 'ebird_small_20190328'\n",
    "lifelist_filename = 'lifelist.csv'\n",
    "month = 8\n",
    "day = 20\n",
    "padding = 4\n",
    "num_spots = 5\n",
    "radius_miles = 100\n",
    "\n",
    "my_scores = chaser(\n",
    "    engine_path,\n",
    "    table_name,\n",
    "    lifelist_filename,\n",
    "    month,\n",
    "    day,\n",
    "    padding,\n",
    "    num_spots,\n",
    "    radius_miles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All days, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Vincenty is deprecated and is going to be removed in geopy 2.0. Use `geopy.distance.geodesic` (or the default `geopy.distance.distance`) instead, which is more accurate and always converges.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top spot 1: ('32.2212741', '-110.9281611')\n",
      "Number possible targets: 21\n",
      "Most common targets: ['Rufous-winged Sparrow', 'Mexican Whip-poor-will', \"Botteri's Sparrow\", 'Common Poorwill', 'Ladder-backed Woodpecker', 'Bridled Titmouse', \"Cassin's Sparrow\", 'Whiskered Screech-Owl', 'Greater Roadrunner', \"Lucy's Warbler\", \"Scott's Oriole\", \"Abert's Towhee\", 'Canyon Towhee', 'Black-throated Sparrow', 'Elf Owl', 'Phainopepla', 'Black-chinned Hummingbird', 'Cactus Wren', 'Arizona Woodpecker', 'Varied Bunting', 'Broad-billed Hummingbird']\n",
      "\n",
      "Top spot 2: ('31.7310142', '-110.881319')\n",
      "Number possible targets: 21\n",
      "Most common targets: ['Rufous-winged Sparrow', 'Mexican Whip-poor-will', \"Botteri's Sparrow\", 'Common Poorwill', 'Ladder-backed Woodpecker', 'Bridled Titmouse', \"Cassin's Sparrow\", 'Whiskered Screech-Owl', 'Greater Roadrunner', \"Lucy's Warbler\", \"Scott's Oriole\", \"Abert's Towhee\", 'Canyon Towhee', 'Black-throated Sparrow', 'Elf Owl', 'Phainopepla', 'Black-chinned Hummingbird', 'Cactus Wren', 'Arizona Woodpecker', 'Varied Bunting', 'Broad-billed Hummingbird']\n",
      "\n",
      "Top spot 3: ('31.7177294', '-110.1869364')\n",
      "Number possible targets: 21\n",
      "Most common targets: ['Rufous-winged Sparrow', 'Mexican Whip-poor-will', \"Botteri's Sparrow\", 'Common Poorwill', 'Ladder-backed Woodpecker', 'Bridled Titmouse', \"Cassin's Sparrow\", 'Whiskered Screech-Owl', 'Greater Roadrunner', \"Lucy's Warbler\", \"Scott's Oriole\", \"Abert's Towhee\", 'Canyon Towhee', 'Black-throated Sparrow', 'Elf Owl', 'Phainopepla', 'Black-chinned Hummingbird', 'Cactus Wren', 'Arizona Woodpecker', 'Varied Bunting', 'Broad-billed Hummingbird']\n",
      "\n",
      "Top spot 4: ('31.6445404', '-110.5958462')\n",
      "Number possible targets: 21\n",
      "Most common targets: ['Rufous-winged Sparrow', 'Mexican Whip-poor-will', \"Botteri's Sparrow\", 'Common Poorwill', 'Ladder-backed Woodpecker', 'Bridled Titmouse', \"Cassin's Sparrow\", 'Whiskered Screech-Owl', 'Greater Roadrunner', \"Lucy's Warbler\", \"Scott's Oriole\", \"Abert's Towhee\", 'Canyon Towhee', 'Black-throated Sparrow', 'Elf Owl', 'Phainopepla', 'Black-chinned Hummingbird', 'Cactus Wren', 'Arizona Woodpecker', 'Varied Bunting', 'Broad-billed Hummingbird']\n",
      "\n",
      "Top spot 5: ('31.3401517', '-110.9294492')\n",
      "Number possible targets: 21\n",
      "Most common targets: ['Rufous-winged Sparrow', 'Mexican Whip-poor-will', \"Botteri's Sparrow\", 'Common Poorwill', 'Ladder-backed Woodpecker', 'Bridled Titmouse', \"Cassin's Sparrow\", 'Whiskered Screech-Owl', 'Greater Roadrunner', \"Lucy's Warbler\", \"Scott's Oriole\", \"Abert's Towhee\", 'Canyon Towhee', 'Black-throated Sparrow', 'Elf Owl', 'Phainopepla', 'Black-chinned Hummingbird', 'Cactus Wren', 'Arizona Woodpecker', 'Varied Bunting', 'Broad-billed Hummingbird']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('44.5660126', '-67.056427'): 10,\n",
       " ('42.0839551', '-70.0490427'): 8,\n",
       " ('42.687714', '-70.6204365'): 7,\n",
       " ('60.3413913', '-147.1028137'): 6,\n",
       " ('42.6251904', '-70.3616729'): 8,\n",
       " ('35.1678', '-120.69428'): 1,\n",
       " ('52.0503333', '178.3339833'): 2,\n",
       " ('43.8982326', '-69.4348598'): 2,\n",
       " ('36.314222', '-121.8902827'): 1,\n",
       " ('39.4727008', '-123.8042021'): 3,\n",
       " ('58.3287533', '-134.6187401'): 4,\n",
       " ('44.6156447', '-124.0665436'): 7,\n",
       " ('57.4212944', '-150.1391602'): 1,\n",
       " ('70.1355399', '-143.54774'): 7,\n",
       " ('48.5922568', '-123.0304022'): 6,\n",
       " ('70.3123202', '-148.3125114'): 11,\n",
       " ('59.6359965', '-151.5139532'): 4,\n",
       " ('42.992209', '-70.7073972'): 7,\n",
       " ('32.429324', '-80.1469607'): 1,\n",
       " ('38.3044865', '-75.1076889'): 4,\n",
       " ('56.6521699', '-132.9288646'): 3,\n",
       " ('30.2091599', '-88.9791107'): 4,\n",
       " ('57.4991259', '-135.2492523'): 2,\n",
       " ('59.9210867', '-148.0890083'): 6,\n",
       " ('24.545713', '-81.8121761'): 4,\n",
       " ('56.0135866', '-132.6815102'): 3,\n",
       " ('59.5253333', '-178.4236667'): 6,\n",
       " ('45.103577', '-67.1306705'): 10,\n",
       " ('57.2020384', '-153.3068275'): 1,\n",
       " ('41.3014861', '-72.1119044'): 3,\n",
       " ('47.661963', '-122.435841'): 5,\n",
       " ('41.4759174', '-82.1756744'): 1,\n",
       " ('39.4088845', '-123.810854'): 3,\n",
       " ('44.2111184', '-68.718313'): 2,\n",
       " ('31.0706164', '-93.2111835'): 1,\n",
       " ('44.3478561', '-121.7310423'): 4,\n",
       " ('48.7068637', '-113.8018545'): 2,\n",
       " ('30.8773', '-98.438'): 6,\n",
       " ('71.3870157', '-156.4774776'): 7,\n",
       " ('26.5498192', '-99.1661596'): 12,\n",
       " ('39.8020431', '-105.513382'): 11,\n",
       " ('37.8089702', '-119.5661831'): 6,\n",
       " ('46.2529981', '-121.5115356'): 4,\n",
       " ('36.8171698', '-111.6301489'): 2,\n",
       " ('48.602636', '-102.4386493'): 9,\n",
       " ('48.3446698', '-122.6696062'): 12,\n",
       " ('31.7310142', '-110.881319'): 21,\n",
       " ('46.0625', '-93.05112'): 2,\n",
       " ('41.7141347', '-121.5111723'): 12,\n",
       " ('38.586068', '-107.696981'): 1,\n",
       " ('27.0446212', '-99.4444013'): 12,\n",
       " ('40.8429942', '-72.4762005'): 3,\n",
       " ('39.4607765', '-121.2835395'): 1,\n",
       " ('33.7780824', '-117.7605691'): 7,\n",
       " ('48.5261266', '-121.4272928'): 11,\n",
       " ('33.8291074', '-108.6266541'): 2,\n",
       " ('44.0893', '-123.2945'): 8,\n",
       " ('33.0364889', '-96.6640522'): 1,\n",
       " ('30.1041849', '-98.8038898'): 6,\n",
       " ('40.9484721', '-111.8752277'): 1,\n",
       " ('36.7141014', '-112.2166944'): 2,\n",
       " ('55.9226622', '-130.0332785'): 1,\n",
       " ('33.4352651', '-111.9057083'): 1,\n",
       " ('29.4241295', '-98.4935913'): 5,\n",
       " ('30.4112444', '-81.4206594'): 2,\n",
       " ('36.0667407', '-114.807204'): 3,\n",
       " ('44.3356036', '-111.4671439'): 2,\n",
       " ('41.78981', '-69.98976'): 7,\n",
       " ('27.8275297', '-97.0789558'): 1,\n",
       " ('25.4686909', '-80.4775772'): 3,\n",
       " ('46.8244373', '-117.2091866'): 1,\n",
       " ('37.5534237', '-121.5735054'): 4,\n",
       " ('48.7208672', '-120.6694722'): 10,\n",
       " ('37.2863457', '-97.8133392'): 1,\n",
       " ('28.9097983', '-97.5023746'): 2,\n",
       " ('60.1127765', '-149.398613'): 4,\n",
       " ('29.95041', '-96.25579'): 1,\n",
       " ('37.250759', '-122.3110485'): 4,\n",
       " ('44.0051', '-122.9631'): 7,\n",
       " ('36.6175679', '-118.6977052'): 4,\n",
       " ('40.044253', '-105.1867721'): 11,\n",
       " ('48.8859802', '-118.5969583'): 1,\n",
       " ('39.3038857', '-123.7743652'): 3,\n",
       " ('40.466667', '-67.7'): 1,\n",
       " ('32.2212741', '-110.9281611'): 21,\n",
       " ('59.3335', '-178.3401667'): 6,\n",
       " ('31.6445404', '-110.5958462'): 21,\n",
       " ('42.34688', '-119.81294'): 2,\n",
       " ('31.7177294', '-110.1869364'): 21,\n",
       " ('36.4238249', '-115.3838789'): 3,\n",
       " ('46.8926658', '-120.796566'): 5,\n",
       " ('34.25', '-99.58333'): 1,\n",
       " ('48.82721', '-100.44542'): 1,\n",
       " ('25.9930992', '-97.1493988'): 3,\n",
       " ('31.3401517', '-110.9294492'): 21,\n",
       " ('25.77428', '-80.19367'): 3,\n",
       " ('41.1179038', '-107.1582696'): 1,\n",
       " ('45.731273', '-103.4423035'): 1,\n",
       " ('40.42477', '-105.75353'): 12,\n",
       " ('34.7678626', '-98.2882212'): 2,\n",
       " ('44.0015513', '-69.4019544'): 2,\n",
       " ('35.521761', '-101.75867'): 2,\n",
       " ('38.8904984', '-122.3169923'): 4,\n",
       " ('38.0061969', '-122.4944794'): 4,\n",
       " ('59.4513054', '-135.3035917'): 1,\n",
       " ('41.0793102', '-122.9388571'): 3,\n",
       " ('41.1798168', '-105.7175732'): 6,\n",
       " ('24.6804014', '-81.4071465'): 4,\n",
       " ('44.00178', '-72.9296'): 1,\n",
       " ('41.212128', '-124.00476'): 4,\n",
       " ('44.7427212', '-93.6159462'): 1,\n",
       " ('37.9100288', '-119.2577559'): 6,\n",
       " ('71.38083', '-156.501'): 7,\n",
       " ('58.4985736', '-134.8861542'): 4,\n",
       " ('47.1790373', '-120.5909586'): 2,\n",
       " ('36.0359891', '-106.8481923'): 3,\n",
       " ('42.3849228', '-106.7383575'): 1,\n",
       " ('39.6569444', '-105.2194444'): 11,\n",
       " ('39.9879059', '-111.6983414'): 4,\n",
       " ('48.2318198', '-121.528101'): 12,\n",
       " ('34.7549283', '-98.3172123'): 2,\n",
       " ('35.8854175', '-106.3228632'): 3,\n",
       " ('34.7250677', '-118.7277552'): 2,\n",
       " ('38.4598604', '-109.8206502'): 1,\n",
       " ('45.1893567', '-71.1912346'): 1,\n",
       " ('64.541256', '-165.406628'): 3,\n",
       " ('45.91715', '-89.24433'): 1,\n",
       " ('46.3253573', '-121.759519'): 4,\n",
       " ('40.3763669', '-105.6520844'): 12,\n",
       " ('37.2620023', '-107.0127205'): 1,\n",
       " ('43.8729007', '-74.4128036'): 1,\n",
       " ('40.5389646', '-121.6088676'): 2,\n",
       " ('42.38253', '-119.83964'): 2,\n",
       " ('33.8372351', '-117.7554989'): 7,\n",
       " ('43.7141062', '-89.2543876'): 1,\n",
       " ('40.8974897', '-102.6712704'): 1,\n",
       " ('43.9852', '-72.9372'): 1,\n",
       " ('37.3556519', '-113.1072922'): 4,\n",
       " ('48.6382262', '-121.3147902'): 10,\n",
       " ('34.8520813', '-119.1719742'): 2,\n",
       " ('60.8127808', '-148.5804749'): 5,\n",
       " ('44.3324439', '-120.8248901'): 4,\n",
       " ('28.5753263', '-80.9966826'): 1,\n",
       " ('33.6965128', '-118.0451372'): 7,\n",
       " ('48.4862966', '-114.3537712'): 2,\n",
       " ('39.7971944', '-111.8188477'): 4,\n",
       " ('40.1063058', '-105.3279233'): 11,\n",
       " ('39.4534671', '-123.8126918'): 3,\n",
       " ('42.9736526', '-70.7647414'): 7,\n",
       " ('32.4879724', '-93.745206'): 1,\n",
       " ('40.0159146', '-105.3412485'): 11,\n",
       " ('30.4128402', '-88.4078837'): 4,\n",
       " ('43.4244873', '-114.024353'): 1,\n",
       " ('42.9172122', '-115.8583832'): 1,\n",
       " ('47.912085', '-122.5265694'): 9,\n",
       " ('37.2521234', '-119.1801352'): 9,\n",
       " ('36.15399', '-95.99277'): 1,\n",
       " ('39.9006414', '-119.5539093'): 1,\n",
       " ('47.7399294', '-123.4374261'): 4,\n",
       " ('40.5055768', '-121.3536072'): 2,\n",
       " ('35.2501716', '-91.5827289'): 2,\n",
       " ('42.4430471', '-122.3146856'): 1,\n",
       " ('48.865', '-121.67'): 11,\n",
       " ('41.672752', '-87.60939'): 1,\n",
       " ('40.8538774', '-124.1329336'): 3,\n",
       " ('42.5332343', '-113.5392548'): 1,\n",
       " ('47.3497293', '-114.7606341'): 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_path = \"/Volumes/seagate-storage/db/ebird_small.db\"\n",
    "table_name = 'ebird_small_20190328'\n",
    "lifelist_filename = 'tessa-lifelist.csv'\n",
    "month = 7\n",
    "day = 2\n",
    "padding = 184\n",
    "num_spots = 5\n",
    "radius_miles = 100\n",
    "\n",
    "tessa_scores_all = chaser(\n",
    "    engine_path,\n",
    "    table_name,\n",
    "    lifelist_filename,\n",
    "    month,\n",
    "    day,\n",
    "    padding,\n",
    "    num_spots,\n",
    "    radius_miles\n",
    ")\n",
    "\n",
    "tessa_scores_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All days, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top spot 1: ('44.5660126', '-67.056427')\n",
      "Number possible targets: 6\n",
      "Most common targets: ['Atlantic Puffin', 'Manx Shearwater', \"Wilson's Storm-Petrel\", 'Razorbill', 'Black Guillemot', 'Great Shearwater']\n",
      "\n",
      "Top spot 2: ('42.992209', '-70.7073972')\n",
      "Number possible targets: 4\n",
      "Most common targets: [\"Wilson's Storm-Petrel\", 'Great Shearwater', 'Roseate Tern', 'Manx Shearwater']\n",
      "\n",
      "Top spot 3: ('42.9736526', '-70.7647414')\n",
      "Number possible targets: 4\n",
      "Most common targets: [\"Wilson's Storm-Petrel\", 'Great Shearwater', 'Roseate Tern', 'Manx Shearwater']\n",
      "\n",
      "Top spot 4: ('42.687714', '-70.6204365')\n",
      "Number possible targets: 4\n",
      "Most common targets: [\"Wilson's Storm-Petrel\", 'Great Shearwater', 'Manx Shearwater', 'Roseate Tern']\n",
      "\n",
      "Top spot 5: ('42.6251904', '-70.3616729')\n",
      "Number possible targets: 4\n",
      "Most common targets: [\"Wilson's Storm-Petrel\", 'Great Shearwater', 'Manx Shearwater', 'Roseate Tern']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: Vincenty is deprecated and is going to be removed in geopy 2.0. Use `geopy.distance.geodesic` (or the default `geopy.distance.distance`) instead, which is more accurate and always converges.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('44.5660126', '-67.056427'): 6,\n",
       " ('42.0839551', '-70.0490427'): 4,\n",
       " ('42.687714', '-70.6204365'): 4,\n",
       " ('42.6251904', '-70.3616729'): 4,\n",
       " ('43.8982326', '-69.4348598'): 1,\n",
       " ('57.4212944', '-150.1391602'): 1,\n",
       " ('42.992209', '-70.7073972'): 4,\n",
       " ('32.429324', '-80.1469607'): 1,\n",
       " ('38.3044865', '-75.1076889'): 2,\n",
       " ('70.3123202', '-148.3125114'): 2,\n",
       " ('59.5253333', '-178.4236667'): 1,\n",
       " ('41.4759174', '-82.1756744'): 1,\n",
       " ('40.8429942', '-72.4762005'): 2,\n",
       " ('37.5534237', '-121.5735054'): 1,\n",
       " ('40.466667', '-67.7'): 1,\n",
       " ('44.0893', '-123.2945'): 1,\n",
       " ('25.77428', '-80.19367'): 1,\n",
       " ('38.8904984', '-122.3169923'): 1,\n",
       " ('24.6804014', '-81.4071465'): 1,\n",
       " ('44.00178', '-72.9296'): 1,\n",
       " ('71.38083', '-156.501'): 1,\n",
       " ('43.8729007', '-74.4128036'): 1,\n",
       " ('43.9852', '-72.9372'): 1,\n",
       " ('28.5753263', '-80.9966826'): 1,\n",
       " ('42.9736526', '-70.7647414'): 4,\n",
       " ('37.2521234', '-119.1801352'): 1,\n",
       " ('40.8538774', '-124.1329336'): 1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_path = \"/Volumes/seagate-storage/db/ebird_small.db\"\n",
    "table_name = 'ebird_small_20190328'\n",
    "lifelist_filename = 'bryan-lifelist.csv'\n",
    "month = 7\n",
    "day = 2\n",
    "padding = 184\n",
    "num_spots = 5\n",
    "radius_miles = 100\n",
    "\n",
    "bryan_scores_all = chaser(\n",
    "    engine_path,\n",
    "    table_name,\n",
    "    lifelist_filename,\n",
    "    month,\n",
    "    day,\n",
    "    padding,\n",
    "    num_spots,\n",
    "    radius_miles\n",
    ")\n",
    "\n",
    "bryan_scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('42.6251904', '-70.3616729'): ['Manx Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Pomarine Jaeger',\n",
       "  'Great Shearwater',\n",
       "  'Northern Gannet',\n",
       "  'Common Eider',\n",
       "  \"Cory's Shearwater\",\n",
       "  \"Leach's Storm-Petrel\",\n",
       "  'Parasitic Jaeger',\n",
       "  'Black-legged Kittiwake',\n",
       "  'Roseate Tern',\n",
       "  'Little Gull'],\n",
       " ('42.687714', '-70.6204365'): [\"Cory's Shearwater\",\n",
       "  'Great Shearwater',\n",
       "  'Parasitic Jaeger',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Roseate Tern',\n",
       "  'Northern Gannet',\n",
       "  'Manx Shearwater',\n",
       "  'Black-legged Kittiwake',\n",
       "  'Atlantic Puffin',\n",
       "  'Black Guillemot',\n",
       "  \"Leach's Storm-Petrel\",\n",
       "  'Little Gull',\n",
       "  'Common Eider',\n",
       "  'Pomarine Jaeger'],\n",
       " ('40.00081', '-69.61919'): ['Great Shearwater', \"Wilson's Storm-Petrel\"],\n",
       " ('60.3062623', '-172.1920681'): ['Short-tailed Shearwater',\n",
       "  'Northern Fulmar',\n",
       "  'Black-legged Kittiwake',\n",
       "  'Glaucous Gull',\n",
       "  'Crested Auklet'],\n",
       " ('40.70982', '-69.4658'): ['Manx Shearwater',\n",
       "  \"Cory's Shearwater\",\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater',\n",
       "  'Long-tailed Jaeger'],\n",
       " ('40.29131', '-69.12693'): [\"Cory's Shearwater\",\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater'],\n",
       " ('42.0839551', '-70.0490427'): ['Manx Shearwater',\n",
       "  'Great Shearwater',\n",
       "  'Northern Gannet',\n",
       "  'Parasitic Jaeger',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  \"Cory's Shearwater\"],\n",
       " ('40.80457', '-69.44293'): ['Manx Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater'],\n",
       " ('39.8751', '-69.53665'): ['Great Shearwater', \"Wilson's Storm-Petrel\"],\n",
       " ('39.99024', '-68.99944'): [\"Wilson's Storm-Petrel\",\n",
       "  \"Audubon's Shearwater\",\n",
       "  'Great Shearwater'],\n",
       " ('40.65276', '-69.35452'): ['Great Shearwater',\n",
       "  'Manx Shearwater',\n",
       "  'Red Phalarope',\n",
       "  \"Wilson's Storm-Petrel\"],\n",
       " ('44.6156447', '-124.0665436'): ['Common Murre', 'Red Phalarope'],\n",
       " ('40.00742', '-68.99939'): [\"Wilson's Storm-Petrel\",\n",
       "  \"Audubon's Shearwater\",\n",
       "  'Great Shearwater'],\n",
       " ('41.04359', '-69.58914'): ['Great Shearwater',\n",
       "  'Manx Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Parasitic Jaeger'],\n",
       " ('41.20005', '-69.68396'): ['Great Shearwater', \"Wilson's Storm-Petrel\"],\n",
       " ('37.1211459', '-122.3402953'): ['Buff-breasted Sandpiper'],\n",
       " ('31.5208333', '-80.2161111'): ['Sooty Tern',\n",
       "  \"Cory's Shearwater\",\n",
       "  'Bridled Tern',\n",
       "  \"Audubon's Shearwater\"],\n",
       " ('38.5095795', '-74.7674561'): [\"Wilson's Storm-Petrel\",\n",
       "  \"Audubon's Shearwater\",\n",
       "  \"Cory's Shearwater\",\n",
       "  'South Polar Skua'],\n",
       " ('31.8333333', '-80.3333333'): ['Bridled Tern'],\n",
       " ('40.30519', '-69.16241'): [\"Cory's Shearwater\",\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater'],\n",
       " ('40.46555', '-69.84608'): ['Great Shearwater'],\n",
       " ('40.43502', '-69.20979'): ['Great Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  \"Cory's Shearwater\"],\n",
       " ('39.93312', '-69.38759'): [\"Wilson's Storm-Petrel\", 'Great Shearwater'],\n",
       " ('39.4727008', '-123.8042021'): ['Buff-breasted Sandpiper',\n",
       "  'Pacific Golden-Plover'],\n",
       " ('40.56525', '-69.30376'): [\"Wilson's Storm-Petrel\",\n",
       "  'Manx Shearwater',\n",
       "  'Red Phalarope'],\n",
       " ('44.104598', '-67.9150772'): ['Great Shearwater', \"Wilson's Storm-Petrel\"],\n",
       " ('40.6233341', '-73.5014534'): ['American Golden-Plover',\n",
       "  'Saltmarsh Sparrow'],\n",
       " ('31.3', '-79.8666667'): [\"Audubon's Shearwater\",\n",
       "  'Sooty Tern',\n",
       "  'Bridled Tern'],\n",
       " ('32.4263402', '-78.9532471'): ['White-tailed Tropicbird'],\n",
       " ('48.5922568', '-123.0304022'): ['Common Murre',\n",
       "  'Northwestern Crow',\n",
       "  'Marbled Murrelet',\n",
       "  'Rhinoceros Auklet',\n",
       "  'Pacific Wren',\n",
       "  'Tufted Puffin',\n",
       "  'Mew Gull',\n",
       "  'Parasitic Jaeger'],\n",
       " ('39.4088845', '-123.810854'): [\"Vaux's Swift\", 'Common Murre'],\n",
       " ('42.2594313', '-70.2831427'): ['Manx Shearwater',\n",
       "  'Great Shearwater',\n",
       "  'Northern Gannet',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Red Phalarope'],\n",
       " ('40.84656', '-70.11282'): [\"Cory's Shearwater\",\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Manx Shearwater'],\n",
       " ('41.832863', '-124.2165756'): ['Parasitic Jaeger',\n",
       "  \"Vaux's Swift\",\n",
       "  'Cackling Goose'],\n",
       " ('19.6927852', '-155.1839535'): ['Chinese Hwamei',\n",
       "  'Hawaii Elepaio',\n",
       "  'Omao',\n",
       "  'Japanese White-eye',\n",
       "  'Apapane'],\n",
       " ('19.6482527', '-155.3710127'): ['Omao',\n",
       "  'Red-billed Leiothrix',\n",
       "  'Hawaii Amakihi',\n",
       "  'Hawaii Akepa',\n",
       "  'Akiapolaau',\n",
       "  'Kalij Pheasant',\n",
       "  'Hawaii Elepaio',\n",
       "  'Hawaii Creeper',\n",
       "  'Apapane',\n",
       "  'Yellow-fronted Canary',\n",
       "  'Hawaiian Hawk'],\n",
       " ('42.1019161', '-70.3320265'): ['Manx Shearwater',\n",
       "  'Roseate Tern',\n",
       "  'Great Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  \"Cory's Shearwater\",\n",
       "  'Northern Gannet',\n",
       "  'Common Eider'],\n",
       " ('42.992209', '-70.7073972'): [\"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater',\n",
       "  'Northern Gannet',\n",
       "  'Parasitic Jaeger'],\n",
       " ('22.2072115', '-159.4754791'): ['Hawaiian Duck', 'Hawaiian Coot'],\n",
       " ('70.1355399', '-143.54774'): ['Glaucous Gull',\n",
       "  'Common Eider',\n",
       "  'American Golden-Plover',\n",
       "  'Parasitic Jaeger',\n",
       "  'King Eider',\n",
       "  'Slaty-backed Gull',\n",
       "  'Mew Gull'],\n",
       " ('70.3123202', '-148.3125114'): ['Glaucous Gull',\n",
       "  'King Eider',\n",
       "  'Cackling Goose',\n",
       "  'Black Guillemot',\n",
       "  'Parasitic Jaeger'],\n",
       " ('44.4441366', '-68.3189964'): ['Black Guillemot', 'Common Eider'],\n",
       " ('22.150861', '-159.6221217'): ['Kauai Elepaio'],\n",
       " ('40.577', '-69.94707'): [\"Wilson's Storm-Petrel\", 'Great Shearwater'],\n",
       " ('41.29177', '-69.80276'): ['Northern Gannet', \"Wilson's Storm-Petrel\"],\n",
       " ('48.2986787', '-122.7238317'): ['Mew Gull'],\n",
       " ('36.8048866', '-121.9812012'): ['Arctic Tern',\n",
       "  'Pomarine Jaeger',\n",
       "  \"Buller's Shearwater\",\n",
       "  'South Polar Skua',\n",
       "  'Common Murre',\n",
       "  'Black-footed Albatross',\n",
       "  'Pink-footed Shearwater',\n",
       "  'Rhinoceros Auklet',\n",
       "  'Ashy Storm-Petrel',\n",
       "  'Parasitic Jaeger',\n",
       "  'Long-tailed Jaeger'],\n",
       " ('21.3876751', '-157.9822954'): ['Red-crested Cardinal',\n",
       "  'Common Waxbill',\n",
       "  'Pacific Golden-Plover',\n",
       "  'Japanese White-eye',\n",
       "  'Common Myna',\n",
       "  'Red-vented Bulbul',\n",
       "  'Red Avadavat',\n",
       "  'Chestnut Munia'],\n",
       " ('40.96149', '-70.1886'): [\"Wilson's Storm-Petrel\"],\n",
       " ('38.3044865', '-75.1076889'): ['Hudsonian Godwit', 'American Flamingo'],\n",
       " ('28.6089384', '-80.8048725'): ['Common Ground-Dove'],\n",
       " ('39.88641', '-69.40244'): ['Great Shearwater',\n",
       "  'Band-rumped Storm-Petrel',\n",
       "  \"Audubon's Shearwater\",\n",
       "  \"Wilson's Storm-Petrel\"],\n",
       " ('46.9104643', '-124.1960621'): ['Long-tailed Jaeger',\n",
       "  'Red Phalarope',\n",
       "  \"Buller's Shearwater\",\n",
       "  'Short-tailed Shearwater'],\n",
       " ('41.3014861', '-72.1119044'): ['Saltmarsh Sparrow'],\n",
       " ('47.6185322', '-122.4102259'): ['Common Murre'],\n",
       " ('40.69648', '-69.36254'): ['Hudsonian Godwit',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  'Great Shearwater'],\n",
       " ('38.5180863', '-74.6466064'): ['South Polar Skua'],\n",
       " ('31.658333', '-80.4275'): [\"Cory's Shearwater\", 'Bridled Tern'],\n",
       " ('40.45433', '-69.2211'): ['Great Shearwater',\n",
       "  \"Wilson's Storm-Petrel\",\n",
       "  \"Cory's Shearwater\"],\n",
       " ('45.5231871', '-123.954277'): ['Marbled Murrelet',\n",
       "  'Buff-breasted Sandpiper'],\n",
       " ('40.16605', '-69.08583'): [\"Wilson's Storm-Petrel\"],\n",
       " ('40.06013', '-69.09985'): [\"Audubon's Shearwater\"],\n",
       " ('32.7761882', '-117.2290564'): ['Fulvous Whistling-Duck',\n",
       "  'Sharp-tailed Sandpiper'],\n",
       " ('41.4759174', '-82.1756744'): ['American Golden-Plover'],\n",
       " ('41.0648569', '-70.0708008'): [\"Cory's Shearwater\"],\n",
       " ('36.0814305', '-75.7913303'): ['Pomarine Jaeger'],\n",
       " ('33.8372351', '-117.7554989'): ['Black-chinned Hummingbird'],\n",
       " ('47.7950237', '-120.7220221'): [\"Barrow's Goldeneye\",\n",
       "  \"Townsend's Warbler\",\n",
       "  \"Vaux's Swift\"],\n",
       " ('19.6923986', '-155.1778738'): ['Chinese Hwamei',\n",
       "  'Hawaii Elepaio',\n",
       "  'Omao',\n",
       "  'Japanese White-eye',\n",
       "  'Apapane'],\n",
       " ('36.061034', '-107.9382706'): [\"Virginia's Warbler\", 'Scaled Quail'],\n",
       " ('41.6413891', '-83.2405672'): ['American Golden-Plover'],\n",
       " ('38.5119131', '-107.0213204'): [\"MacGillivray's Warbler\",\n",
       "  'Black-billed Magpie'],\n",
       " ('40.3141441', '-105.404846'): [\"Williamson's Sapsucker\"],\n",
       " ('34.8741723', '-111.7596245'): ['Greater Roadrunner'],\n",
       " ('31.7310142', '-110.881319'): [\"Bell's Vireo\",\n",
       "  'Bridled Titmouse',\n",
       "  'Arizona Woodpecker',\n",
       "  'Sulphur-bellied Flycatcher',\n",
       "  'Verdin',\n",
       "  \"Cassin's Sparrow\",\n",
       "  'Mexican Jay',\n",
       "  'Canyon Towhee',\n",
       "  'Curve-billed Thrasher',\n",
       "  'Greater Roadrunner',\n",
       "  'Ladder-backed Woodpecker',\n",
       "  'Canyon Wren',\n",
       "  'Rock Wren',\n",
       "  \"Scott's Oriole\",\n",
       "  'Phainopepla',\n",
       "  'Hepatic Tanager',\n",
       "  'Varied Bunting'],\n",
       " ('26.5498192', '-99.1661596'): ['Red-billed Pigeon',\n",
       "  'Groove-billed Ani',\n",
       "  \"Couch's Kingbird\",\n",
       "  'Green Jay',\n",
       "  'Ladder-backed Woodpecker',\n",
       "  'Golden-fronted Woodpecker'],\n",
       " ('48.1947891', '-93.8032051'): ['Black-backed Woodpecker'],\n",
       " ('39.6569444', '-105.2194444'): ['Broad-tailed Hummingbird',\n",
       "  \"Woodhouse's Scrub-Jay\",\n",
       "  'Canyon Wren',\n",
       "  \"Virginia's Warbler\",\n",
       "  'Rock Wren'],\n",
       " ('43.8405363', '-124.1726089'): ['Pink-footed Shearwater',\n",
       "  'Fork-tailed Storm-Petrel'],\n",
       " ('29.4704637', '-94.6026707'): ['Scissor-tailed Flycatcher'],\n",
       " ('35.2501716', '-91.5827289'): ['Buff-breasted Sandpiper',\n",
       "  'Wood Stork',\n",
       "  'Scissor-tailed Flycatcher',\n",
       "  'American Golden-Plover'],\n",
       " ('41.7141347', '-121.5111723'): ['Pinyon Jay',\n",
       "  'Black-billed Magpie',\n",
       "  \"Williamson's Sapsucker\",\n",
       "  'Gray Flycatcher',\n",
       "  'Canyon Wren',\n",
       "  'Eared Grebe',\n",
       "  \"Lewis's Woodpecker\"],\n",
       " ('39.595949', '-75.2396965'): ['Buff-breasted Sandpiper'],\n",
       " ('32.3856344', '-112.8541522'): ['Brown-crested Flycatcher',\n",
       "  'Gila Woodpecker',\n",
       "  'Cactus Wren'],\n",
       " ('46.7591453', '-92.0834835'): ['Buff-breasted Sandpiper'],\n",
       " ('35.66591', '-75.4799'): ['American Golden-Plover'],\n",
       " ('33.7780824', '-117.7605691'): ['Red-crowned Parrot',\n",
       "  'California Gnatcatcher',\n",
       "  'Cactus Wren',\n",
       "  'Cinnamon Teal'],\n",
       " ('39.5447356', '-106.2420978'): ['Pine Grosbeak'],\n",
       " ('38.2611314', '-121.4084959'): ['Lazuli Bunting',\n",
       "  'Black-chinned Hummingbird'],\n",
       " ('32.4295707', '-93.701118'): ['Buff-breasted Sandpiper'],\n",
       " ('28.2018', '-81.393'): ['Limpkin'],\n",
       " ('31.85591', '-106.63955'): ['Lark Bunting', 'Prairie Falcon'],\n",
       " ('47.628', '-117.53239'): ['Gray Partridge'],\n",
       " ('27.8275297', '-97.0789558'): ['Mottled Duck'],\n",
       " ('33.3771201', '-108.9071381'): ['Lazuli Bunting'],\n",
       " ('38.1519218', '-85.7329059'): ['Buff-breasted Sandpiper'],\n",
       " ('41.8375089', '-88.5121168'): ['American Golden-Plover'],\n",
       " ('32.25287', '-109.83162'): ['Cinnamon Teal', 'Chihuahuan Raven'],\n",
       " ('40.94929', '-69.50775'): [\"Wilson's Storm-Petrel\"],\n",
       " ('40.8429942', '-72.4762005'): [\"Wilson's Storm-Petrel\", 'Roseate Tern'],\n",
       " ('37.1774495', '-122.1893835'): ['Western Screech-Owl'],\n",
       " ('37.2752991', '-107.8796234'): [\"Woodhouse's Scrub-Jay\",\n",
       "  \"Lewis's Woodpecker\"],\n",
       " ('33.10952', '-91.26201'): ['Wood Stork'],\n",
       " ('41.4098', '-69.9869'): ['Common Eider'],\n",
       " ('33.0959638', '-116.9994593'): [\"Lawrence's Goldfinch\",\n",
       "  'Common Ground-Dove'],\n",
       " ('47.7890267', '-120.868578'): [\"Townsend's Warbler\", 'Black Swift'],\n",
       " ('31.9164362', '-109.2737471'): ['Broad-tailed Hummingbird',\n",
       "  \"Townsend's Warbler\",\n",
       "  'Yellow-eyed Junco',\n",
       "  'Mexican Chickadee',\n",
       "  \"Virginia's Warbler\"],\n",
       " ('59.4513054', '-135.3035917'): ['Varied Thrush'],\n",
       " ('40.8538774', '-124.1329336'): ['Cinnamon Teal'],\n",
       " ('40.044253', '-105.1867721'): ['Black-billed Magpie',\n",
       "  'Yellow-headed Blackbird',\n",
       "  'Cinnamon Teal'],\n",
       " ('25.4686909', '-80.4775772'): ['Common Myna'],\n",
       " ('27.0446212', '-99.4444013'): [\"Morelet's Seedeater\",\n",
       "  'Olive Sparrow',\n",
       "  'Common Ground-Dove',\n",
       "  \"Couch's Kingbird\"],\n",
       " ('34.1868849', '-109.9833155'): ['Yellow-headed Blackbird',\n",
       "  'Cinnamon Teal',\n",
       "  \"Grace's Warbler\",\n",
       "  \"MacGillivray's Warbler\"],\n",
       " ('30.1041849', '-98.8038898'): ['Ladder-backed Woodpecker'],\n",
       " ('28.5353697', '-96.9097137'): ['Cave Swallow', 'Wood Stork'],\n",
       " ('19.6444889', '-155.3237092'): ['Japanese White-eye',\n",
       "  'Omao',\n",
       "  'Hawaii Elepaio'],\n",
       " ('28.5753263', '-80.9966826'): ['Mottled Duck',\n",
       "  'Limpkin',\n",
       "  'Common Ground-Dove'],\n",
       " ('37.4752157', '-94.6981841'): ['Scissor-tailed Flycatcher'],\n",
       " ('26.55474', '-97.42496'): ['Pyrrhuloxia', 'Cave Swallow'],\n",
       " ('40.429675', '-91.5547167'): [\"Bell's Vireo\"],\n",
       " ('38.2289099', '-122.5980878'): ['Pacific Golden-Plover', \"Ridgway's Rail\"],\n",
       " ('21.3988971', '-157.7986908'): ['Java Sparrow',\n",
       "  'Hawaiian Coot',\n",
       "  'Japanese White-eye',\n",
       "  'Pacific Golden-Plover',\n",
       "  'Great Frigatebird',\n",
       "  'Red-vented Bulbul',\n",
       "  'Black Noddy'],\n",
       " ('29.4241295', '-98.4935913'): ['Inca Dove',\n",
       "  'Golden-fronted Woodpecker',\n",
       "  'Scissor-tailed Flycatcher',\n",
       "  'Buff-breasted Sandpiper'],\n",
       " ('37.8948386', '-122.5017214'): [\"Ridgway's Rail\"],\n",
       " ('26.8812473', '-99.2507401'): ['Pyrrhuloxia'],\n",
       " ('19.9682847', '-155.3212906'): ['Apapane',\n",
       "  'Hawaii Elepaio',\n",
       "  'Omao',\n",
       "  'Red-billed Leiothrix'],\n",
       " ('46.1699049', '-107.3214483'): ['Black-billed Magpie'],\n",
       " ('29.95041', '-96.25579'): ['Inca Dove', 'Wood Stork'],\n",
       " ('46.0625', '-93.05112'): ['Clay-colored Sparrow'],\n",
       " ('45.1893567', '-71.1912346'): ['Black-backed Woodpecker'],\n",
       " ('35.0691344', '-118.176198'): ['Red-breasted Sapsucker',\n",
       "  \"Lawrence's Goldfinch\",\n",
       "  \"MacGillivray's Warbler\"],\n",
       " ('34.6755962', '-98.615942'): ['Rock Wren', 'Black-capped Vireo'],\n",
       " ('39.0811212', '-77.4389849'): ['American Golden-Plover'],\n",
       " ('34.775143', '-105.544754'): ['Pinyon Jay', \"Cassin's Sparrow\"],\n",
       " ('36.6252236', '-121.9317888'): [\"Townsend's Warbler\"],\n",
       " ('40.6264861', '-73.4784293'): ['American Golden-Plover',\n",
       "  'Saltmarsh Sparrow'],\n",
       " ('47.6232605', '-119.4848585'): ['Eared Grebe', 'Cinnamon Teal'],\n",
       " ('45.2253372', '-90.853672'): ['Clay-colored Sparrow'],\n",
       " ('26.27156', '-81.43111'): ['Common Ground-Dove'],\n",
       " ('39.92373', '-69.00208'): [\"Wilson's Storm-Petrel\"],\n",
       " ('34.3770694', '-118.4681726'): [\"Costa's Hummingbird\", 'Phainopepla'],\n",
       " ('34.3930006', '-119.5140259'): [\"MacGillivray's Warbler\"],\n",
       " ('41.7960139', '-87.5765064'): ['Connecticut Warbler'],\n",
       " ('44.1291227', '-121.3307548'): ['Black-billed Magpie',\n",
       "  \"MacGillivray's Warbler\"],\n",
       " ('47.3612693', '-116.7396069'): [\"MacGillivray's Warbler\"],\n",
       " ('38.5838177', '-121.6354752'): [\"MacGillivray's Warbler\", 'Lazuli Bunting'],\n",
       " ('30.7214731', '-92.348671'): ['Fulvous Whistling-Duck'],\n",
       " ('31.5427632', '-110.1337928'): ['Mexican Duck',\n",
       "  'Black-throated Sparrow',\n",
       "  \"Cassin's Sparrow\",\n",
       "  \"Lucy's Warbler\",\n",
       "  'Lazuli Bunting',\n",
       "  'Gray Hawk',\n",
       "  'Tropical Kingbird'],\n",
       " ('32.4170301', '-110.7250857'): [\"Cassin's Vireo\",\n",
       "  'Broad-tailed Hummingbird',\n",
       "  'Arizona Woodpecker',\n",
       "  \"Rivoli's Hummingbird\"],\n",
       " ('41.212128', '-124.00476'): ['Marbled Murrelet', 'Pacific Wren'],\n",
       " ('34.3963633', '-106.8910555'): ['Lark Bunting'],\n",
       " ('33.07391', '-106.71396'): ['Black-chinned Sparrow',\n",
       "  \"Scott's Oriole\",\n",
       "  'Pinyon Jay',\n",
       "  'Rock Wren'],\n",
       " ('41.505492', '-71.0532188'): ['Roseate Tern'],\n",
       " ('32.9927552', '-115.5427408'): ['Black-chinned Hummingbird'],\n",
       " ('32.4879724', '-93.745206'): ['Inca Dove'],\n",
       " ('42.3803902', '-72.5231323'): ['American Golden-Plover'],\n",
       " ('26.7294962', '-81.8611339'): ['Common Ground-Dove'],\n",
       " ('45.91715', '-89.24433'): ['Northern Goshawk'],\n",
       " ('38.0156401', '-76.1407471'): ['Buff-breasted Sandpiper'],\n",
       " ('39.3256948', '-121.7722893'): [\"MacGillivray's Warbler\"],\n",
       " ('58.5225682', '-134.8283815'): ['Mew Gull'],\n",
       " ('40.7933617', '-77.8600235'): ['Buff-breasted Sandpiper'],\n",
       " ('27.302613', '-80.3727579'): ['Mottled Duck']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False) # Stop kernel from getting to here if \"run all cells\" is accidentally selected :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to read from & number of lines to read\n",
    "#data_file = '/Volumes/seagate-storage/code/ebird_data/medium_dataset.txt']\n",
    "large_data_file = '/Volumes/seagate-storage/code/ebird_data/ebd_relJan-2019.txt'\n",
    "\n",
    "# Which columns to use\n",
    "desired_cols = desired_cols_chaser\n",
    "                          \n",
    "# Of columns, which are dates?\n",
    "date_cols = ['OBSERVATION DATE']\n",
    "\n",
    "# Chunk size to read through data_file\n",
    "chunk_size = 100000\n",
    "\n",
    "# Desired path for SQLITE db; if does not exist, will be created\n",
    "engine_path = \"/Volumes/seagate-storage/db/ebird_chaser.db\"\n",
    "\n",
    "# Name of SQL table\n",
    "table_name = 'ebird_small_20190328'\n",
    "\n",
    "# How many chunks to print after\n",
    "# Should print ~11 times, once every 50*100000 = 50000000 lines\n",
    "X = 50\n",
    "\n",
    "engine = process_data(\n",
    "    engine_path,\n",
    "    large_data_file,\n",
    "    desired_cols,\n",
    "    date_cols,\n",
    "    chunk_size,\n",
    "    table_name,\n",
    "    X\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "* Test amount of time for each type of access of dataset/pandas usage/etc\n",
    "* Store entire DB (or just USA, Canada?)\n",
    "* Do chaser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(\n",
    "    engine_path,\n",
    "    data_path,\n",
    "    desired_cols,\n",
    "    date_cols,\n",
    "    chunk_size,\n",
    "    table_name,\n",
    "    X,\n",
    "    delete_old_table = True\n",
    "):\n",
    "    t0 = time()\n",
    "    \n",
    "    engine = create_engine('sqlite:///' + engine_path)\n",
    "    # If database doesn't already exist, make a new engine\n",
    "    if not database_exists(engine.url):\n",
    "        create_database(engine.url)\n",
    "    # Otherwise, make sure the engine is clear\n",
    "    # Note that it's MUCH faster to delete this from filesystem directly\n",
    "    elif delete_old_table:\n",
    "        meta = MetaData(engine)\n",
    "        meta.reflect() # Find all tables\n",
    "        # Only drop the table we're trying to refill\n",
    "        for tbl in reversed(meta.sorted_tables):\n",
    "            if tbl.name == table_name:\n",
    "                engine.execute(tbl.delete())\n",
    "                print(f'Dropped table {table_name}')\n",
    "        \n",
    "    t1 = time()\n",
    "    \n",
    "    lines_saved_to_db = 0\n",
    "    counter = 0\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        filepath_or_buffer = data_path, \n",
    "        sep = '\\t',\n",
    "        usecols = desired_cols.keys(),\n",
    "        parse_dates = date_cols, \n",
    "        chunksize = chunk_size,\n",
    "        dtype = desired_cols,\n",
    "        na_values = ['X']\n",
    "    ):\n",
    "\n",
    "        chunk.to_sql(\n",
    "            name = table_name,\n",
    "            con = engine,\n",
    "            if_exists = 'append'\n",
    "        )\n",
    "\n",
    "        # Print info every X iterations\n",
    "        # i.e., every chunk_size * X lines\n",
    "        lines_saved_to_db += chunk.shape[0]\n",
    "        if (not counter % X):\n",
    "            print(f\"Iteration {counter}:\")\n",
    "            print(f\"  Lines saved to DB: {lines_saved_to_db}\") #Helpful for only saving year data\n",
    "            print(f\"  Minutes elapsed: {(time()-t1)/60}\\n\")\n",
    "        counter += 1\n",
    "\n",
    "    db_time = (time()-t1)/60\n",
    "    total_time = (time()-t0)/60\n",
    "    estimated_time = ((total_time-db_time) +  (577335302/lines_saved_to_db)*db_time)/60\n",
    "    print(f\"Total iterations: {counter}\")\n",
    "    print(f\"Total lines saved to DB: {lines_saved_to_db}\") #Helpful for only saving year data\n",
    "    print(f\"Minutes elapsed during DB functions: {db_time}\")\n",
    "    print(f\"Total minutes elapsed: {total_time}\")\n",
    "    print(f\"Estimated time for all lines: {estimated_time} hours\")\n",
    "    return engine\n",
    "            \n",
    "engine = process_data(\n",
    "    engine_path,\n",
    "    data_file,\n",
    "    desired_cols,\n",
    "    date_cols,\n",
    "    chunk_size,\n",
    "    table_name,\n",
    "    X\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code that might help with next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = 577335302 #from previous analysis\n",
    "chunk_size = 1000000 # number of lines to read at once\n",
    "num_chunks = 3 # number of chunks to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_cols = [\n",
    "        'Last edited date', \n",
    "        'category', \n",
    "        'common name', \n",
    "        'scientific name', \n",
    "        'observation count', \n",
    "        'country', \n",
    "        'state', \n",
    "        'latitude', \n",
    "        'longitude', \n",
    "        'observation date', \n",
    "        'observer id', \n",
    "        'protocol type',\n",
    "        'ALL SPECIES REPORTED',\n",
    "]\n",
    "\n",
    "desired_cols = [item.upper() for item in the_cols]\n",
    "desired_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_byemeh = pd.DataFrame({'hi':[0, 1, 2], 'bye':[8, 9, 9], 'meh':[42, 42, 20]}, index=[0, 1, 2])[['bye', 'meh']]\n",
    "just_byemeh.loc[just_byemeh['meh'] == 42]\n",
    "\n",
    "just_byemeh.loc[\n",
    "    (just_byemeh['meh'] == 42) & \n",
    "    (just_byemeh['bye'] == 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_db(chunk, table_name, engine):\n",
    "    '''\n",
    "    Process & save data from chunk\n",
    "    \n",
    "    Processes data to identify\n",
    "    \n",
    "    Inputs:\n",
    "        chunk: a dataframe to save\n",
    "        table_name:\n",
    "        engine: SQLAlchemy connection to use\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # For using only 2018 data:\n",
    "    #only_2018 = chunk.loc[\n",
    "    #    (chunk['LAST EDITED DATE'].dt.year == 2018) &\n",
    "    #    (chunk['OBSERVATION DATE'].dt.year == 2018)]\n",
    "    #if only_2018.shape[0]: # if this DF has anything in it (i.e. any 2018 records)\n",
    "    #    only_2018.to_sql('ebird_data_2018', engine, if_exists='append')\n",
    "    #return only_2018\n",
    "\n",
    "engine = create_engine(\"sqlite:////Volumes/seagate-storage/db/ebird_2018.db\")\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "    \n",
    "    \n",
    "    \n",
    "the_cols = [\n",
    "        'Last edited date', \n",
    "        'category', \n",
    "        'common name', \n",
    "        'scientific name', \n",
    "        'observation count', \n",
    "        'country', \n",
    "        'state', \n",
    "        'latitude', \n",
    "        'longitude', \n",
    "        'observation date', \n",
    "        'observer id', \n",
    "        'protocol type',\n",
    "        'ALL SPECIES REPORTED',\n",
    "]\n",
    "\n",
    "desired_cols = [item.upper() for item in the_cols]\n",
    "desired_cols\n",
    "\n",
    "\n",
    "data_file = '/Volumes/seagate-storage/code/evil_project/example_dataset.txt' #'/Volumes/seagate-storage/code/ebird_data/ebd_relJan-2019.txt'\n",
    "\n",
    "\n",
    "num_lines = 577335302 #from previous analysis\n",
    "chunk_size = 1000000 # number of lines to read at once\n",
    "\n",
    "\n",
    "def process(chunk):\n",
    "    \n",
    "    only_2018 = chunk.loc[\n",
    "        (chunk['LAST EDITED DATE'].dt.year == 2018) &\n",
    "        (chunk['OBSERVATION DATE'].dt.year == 2018)]\n",
    "    \n",
    "    if only_2018.shape[0]: # if this DF has anything in it\n",
    "        only_2018.to_sql('ebird_data_2018', engine, if_exists='append')\n",
    "\n",
    "    return only_2018\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "lines_saved_to_db = 0\n",
    "counter = 0\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    data_file, \n",
    "    sep='\\t', \n",
    "    #index_col = ['SAMPLING EVENT IDENTIFIER'],\n",
    "    usecols = desired_cols,\n",
    "    parse_dates = ['LAST EDITED DATE', 'OBSERVATION DATE'], \n",
    "    chunksize=chunk_size):\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    finished_chunk = process(chunk)\n",
    "    lines_saved_to_db += finished_chunk.shape[0]\n",
    "\n",
    "    if not counter % 100:\n",
    "        print(f\"Iteration {counter}:\")\n",
    "        print(f\"  Lines saved to DB: {lines_saved_to_db}\")\n",
    "        print(f\"  Minutes elapsed: {(time.time()-t1)/60}\")\n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "t2 = time.time()\n",
    "\n",
    "process_time = t2-t1\n",
    "print('Time to process rows:', process_time)\n",
    "\n",
    "#est_time = (num_lines/(chunk_size*num_chunks))*process_time\n",
    "#print('Estimated time (seconds) for all rows:', est_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the whole DF:\n",
    "\n",
    "```\n",
    "chunk_size = 1000000 # number of lines to read at once\n",
    "num_chunks = 3 # number of chunks to test on\n",
    "\n",
    "(1000000, 46)\n",
    "(1000000, 46)\n",
    "(1000000, 46)\n",
    "Time to process 3 rows: 23.173866748809814\n",
    "Estimated time for all rows: 4459.697119310624\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "chunk_size = 3000000 # number of lines to read at once\n",
    "num_chunks = 1 # number of chunks to test on\n",
    "\n",
    "(3000000, 46)\n",
    "Time to process rows: 23.521601915359497\n",
    "Estimated time (seconds) for all rows: 4526.6170484426175\n",
    "\n",
    "---\n",
    "\n",
    "chunk_size = 500000 # number of lines to read at once\n",
    "num_chunks = 6 # number of chunks to test on\n",
    "\n",
    "(500000, 46)\n",
    "(500000, 46)\n",
    "(500000, 46)\n",
    "(500000, 46)\n",
    "(500000, 46)\n",
    "(500000, 46)\n",
    "Time to process rows: 24.359390020370483\n",
    "Estimated time (seconds) for all rows: 4687.845264648793\n",
    "```\n",
    "\n",
    "Reading only desired columns, with `parse_dates`\n",
    "```\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "Time to process rows: 13.444914102554321\n",
    "Estimated time (seconds) for all rows: 2587.407847920753\n",
    "```\n",
    "\n",
    "Reading only desired columns, without `parse_dates`:\n",
    "\n",
    "```\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "(500000, 12)\n",
    "Time to process rows: 11.651726961135864\n",
    "Estimated time (seconds) for all rows: 2242.3177679763053\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(small_data_file, sep='\\t').to_sql('test_ebird_data', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "small_data_file = '/Volumes/seagate-storage/code/ebird_data/test_dataset.txt'\n",
    "pd.read_csv(small_data_file, sep='\\t').to_sql('test_ebird_data', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import pandas as pd\n",
    "from functools import wraps\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_db = pd.read_sql('test_ebird_data',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_db.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only the needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func took: {} sec'.format(te-ts))\n",
    "        return result\n",
    "    return wrap\n",
    "\n",
    "\n",
    "def process_chunk(chunk_df):\n",
    "    new_df = chunk_df[['COMMON NAME','LATITUDE', 'LONGITUDE', 'OBSERVATION DATE']]\n",
    "    new_df.to_sql('med_occ', medium_engine, if_exists='append')\n",
    "\n",
    "@timing\n",
    "def process_all_data(engine_path, data_path):\n",
    "    engine = create_engine('sqlite:///'+engine_path)\n",
    "    for chunk in pd.read_csv(data_path, sep='\\t', chunksize=100):\n",
    "        process_chunk(chunk)\n",
    "\n",
    "\n",
    "process_all_data(\n",
    "    engine_path='/Volumes/seagate-storage/db/large_ebird.db', \n",
    "    data_path='/Volumes/seagate-storage/code/ebird_data/large_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_database = database[['COMMON NAME','LATITUDE', 'LONGITUDE', 'OBSERVATION DATE']]\n",
    "small_database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
